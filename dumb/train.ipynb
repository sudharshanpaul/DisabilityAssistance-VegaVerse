{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuj8F7hdxTBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd93d29-301a-4987-ca05-4239cb85ec3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive mounted successfully!\n",
            "Contents of drive: ['processed']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if mount was successful\n",
        "import os\n",
        "print(\"Drive mounted successfully!\")\n",
        "print(\"Contents of drive:\", os.listdir('/content/drive/MyDrive'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install opencv-python\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-rwexIazGJE",
        "outputId": "b2e47de2-10f0-44a4-bc7a-eab43c9ad4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import cv2\n",
        "import json\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "T8Ybk-sVzGHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_BASE_DIR = \"/content/drive/MyDrive/processed\"  # Update this path\n",
        "LABEL_MAP_PATH = \"/content/WLASL_v0.3.json\""
      ],
      "metadata": {
        "id": "GL9XFwM6zGE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_FRAMES = 16  # Use a fixed number of frames per video\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Video base directory: {VIDEO_BASE_DIR}\")\n",
        "print(f\"Label map path: {LABEL_MAP_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju8qrqpozGCz",
        "outputId": "92874ab3-b1f7-4a4e-ccd9-ac8698803011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Video base directory: /content/drive/MyDrive/processed\n",
            "Label map path: /content/WLASL_v0.3.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(VIDEO_BASE_DIR):\n",
        "    print(f\"❌ ERROR: Video base directory not found: {VIDEO_BASE_DIR}\")\n",
        "    print(\"Please update the VIDEO_BASE_DIR path in Section 3\")\n",
        "else:\n",
        "    print(f\"✅ Video base directory found: {VIDEO_BASE_DIR}\")\n",
        "\n",
        "# Check if label map file exists\n",
        "if not os.path.exists(LABEL_MAP_PATH):\n",
        "    print(f\"❌ ERROR: Label map not found: {LABEL_MAP_PATH}\")\n",
        "    print(\"Please update the LABEL_MAP_PATH in Section 3\")\n",
        "else:\n",
        "    print(f\"✅ Label map found: {LABEL_MAP_PATH}\")\n",
        "\n",
        "# Load and process label map\n",
        "try:\n",
        "    with open(LABEL_MAP_PATH, \"r\") as f:\n",
        "        label_data = json.load(f)  # This is a list of dicts\n",
        "        glosses = sorted(set(item[\"gloss\"] for item in label_data))  # Unique gloss names\n",
        "        label_to_idx = {gloss: idx for idx, gloss in enumerate(glosses)}\n",
        "        idx_to_label = {idx: gloss for gloss, idx in label_to_idx.items()}\n",
        "    print(f\"✅ Label map loaded successfully. Number of classes: {len(label_to_idx)}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading label map: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isHyo340zF-W",
        "outputId": "afbfbff2-c25d-485f-99e2-18408469dd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Video base directory found: /content/drive/MyDrive/processed\n",
            "✅ Label map found: /content/WLASL_v0.3.json\n",
            "✅ Label map loaded successfully. Number of classes: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SignDataset(Dataset):\n",
        "    def __init__(self, split_dir, transform=None):\n",
        "        self.video_paths = []\n",
        "        self.labels = []\n",
        "        for root, _, files in os.walk(split_dir):\n",
        "            for f in files:\n",
        "                if f.lower().endswith(\".mp4\"):\n",
        "                    full_path = os.path.join(root, f)\n",
        "                    self.video_paths.append(full_path)\n",
        "                    class_id = os.path.basename(os.path.dirname(full_path))\n",
        "                    self.labels.append(int(class_id))  # class_id like \"0\", \"1\", etc.\n",
        "        if not self.video_paths:\n",
        "            raise RuntimeError(f\"No videos found in {split_dir}\")\n",
        "        self.transform = transform\n",
        "        print(f\"Dataset initialized with {len(self.video_paths)} videos\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        frames = self.load_video(video_path)\n",
        "        return frames, label\n",
        "\n",
        "    def load_video(self, path):\n",
        "        cap = cv2.VideoCapture(path)\n",
        "        frames = []\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            # Convert BGR to RGB for proper color handling\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            if self.transform:\n",
        "                frame = self.transform(frame)\n",
        "            frames.append(frame)\n",
        "        cap.release()\n",
        "\n",
        "        if len(frames) == 0:\n",
        "            raise RuntimeError(f\"No frames extracted from {path}\")\n",
        "\n",
        "        if len(frames) > MAX_FRAMES:\n",
        "            frames = frames[:MAX_FRAMES]\n",
        "        elif len(frames) < MAX_FRAMES:\n",
        "            frames += [frames[-1]] * (MAX_FRAMES - len(frames))\n",
        "\n",
        "        return torch.stack(frames).permute(1, 0, 2, 3)  # (C, T, H, W)"
      ],
      "metadata": {
        "id": "zLVpgRqYzF3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SignLanguageModel(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, num_classes=300):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        self.cnn = nn.Sequential(*list(resnet.children())[:-1])  # remove final FC\n",
        "        self.rnn = nn.GRU(input_size=512, hidden_size=hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T, H, W = x.size()\n",
        "        x = x.permute(0, 2, 1, 3, 4)  # (B, T, C, H, W)\n",
        "        cnn_feats = []\n",
        "        for t in range(T):\n",
        "            out = self.cnn(x[:, t]).squeeze()  # (B, 512)\n",
        "            cnn_feats.append(out)\n",
        "        cnn_feats = torch.stack(cnn_feats, dim=1)  # (B, T, 512)\n",
        "        _, h_n = self.rnn(cnn_feats)\n",
        "        out = self.fc(h_n.squeeze(0))\n",
        "        return out"
      ],
      "metadata": {
        "id": "X6lQYIsKzFwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_split_path = os.path.join(VIDEO_BASE_DIR, \"train\")\n",
        "    print(f\"Looking for training data in: {train_split_path}\")\n",
        "\n",
        "    if os.path.exists(train_split_path):\n",
        "        dataset = SignDataset(train_split_path, transform=transform)\n",
        "        print(f\"✅ Dataset loaded successfully with {len(dataset)} videos\")\n",
        "\n",
        "        # Test loading one sample\n",
        "        sample_video, sample_label = dataset[0]\n",
        "        print(f\"Sample video shape: {sample_video.shape}\")\n",
        "        print(f\"Sample label: {sample_label}\")\n",
        "    else:\n",
        "        print(f\"❌ Training directory not found: {train_split_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading dataset: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0059kBGzFuh",
        "outputId": "d4d536f6-660f-4c2a-b9db-a8a0bbea5f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for training data in: /content/drive/MyDrive/processed/train\n",
            "Dataset initialized with 1897 videos\n",
            "✅ Dataset loaded successfully with 1897 videos\n",
            "Sample video shape: torch.Size([3, 16, 224, 224])\n",
            "Sample label: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_split_path = os.path.join(VIDEO_BASE_DIR, \"train\")\n",
        "    dataset = SignDataset(train_split_path, transform=transform)\n",
        "\n",
        "    # Use drop_last=True to avoid batch size issues\n",
        "    loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    # Determine number of classes from dataset\n",
        "    num_classes = len(set(dataset.labels))\n",
        "    print(f\"Number of classes detected: {num_classes}\")\n",
        "\n",
        "    model = SignLanguageModel(num_classes=num_classes).to(DEVICE)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    print(f\"Total batches per epoch: {len(loader)}\")\n",
        "\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (videos, labels) in enumerate(tqdm(loader, desc=f\"Epoch {epoch+1}\")):\n",
        "            try:\n",
        "                videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
        "                print(f\"Batch {batch_idx}: Video shape: {videos.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "                preds = model(videos)\n",
        "                loss = loss_fn(preds, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = torch.max(preds.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in batch {batch_idx}: {e}\")\n",
        "                print(f\"Video shape: {videos.shape if 'videos' in locals() else 'Not loaded'}\")\n",
        "                break\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        accuracy = 100 * correct / total if total > 0 else 0\n",
        "        print(f\"✅ Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Save model\n",
        "    model_save_path = \"/content/drive/MyDrive/sign_language_model.pth\"\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"✅ Model saved to: {model_save_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 9: RUN TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "# Run training\n",
        "print(\"🚀 Starting Sign Language Model Training...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    train()\n",
        "    print(\"🎉 Training completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Training failed with error: {e}\")\n",
        "    print(\"Please check your data paths and try again.\")"
      ],
      "metadata": {
        "id": "bw5qloqQ0fKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}